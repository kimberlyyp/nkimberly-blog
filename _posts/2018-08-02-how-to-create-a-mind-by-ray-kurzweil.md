---
layout: post
title: "How to Create a Mind by Ray Kurzweil"
date: 2018-08-02 22:51:01 +0000
categories: ['Book Reviews']
---

Ray Kurzweil is a prize-winning author and scientist. He was named Inventor of the Year by MIT in 1988 and was awarded the Dickson Prize, Carnegie Mellon's top science prize, in 1994. He is the recipient of nine honorary doctorates and honors from two American presidents. ([source](https://www.amazon.com/Ray-Kurzweil/e/B001ILHHDS)).

**Book Review #19**
## Review
Consider how you recognize the word "Apple." According to Kurzweil's model, you don't process it letter by letter in sequence. Instead, low-level pattern recognizers fire on features like crossbars and curves, mid-level modules assemble these into letters, and higher-level modules recognize the word, sometimes before you've even registered all five letters. This is why you can read words with missing or jumbled letters, and why you sometimes "see" words that aren't quite there.
This hierarchical pattern recognition model is the core of *How to Create a Mind*, and it's genuinely interesting. But the book gives us the big picture without ever zooming in. I kept waiting for implementation details that never came. Still, the concepts Kurzweil introduces are worth engaging with, and I came away more convinced that machine intelligence is closer than our intuitions suggest.

![38411951_1748745651909196_7351594399853182976_n](https://nkimberly.wordpress.com/wp-content/uploads/2018/08/38411951_1748745651909196_7351594399853182976_n1.jpg?w=1536)
I've grouped my takeaways into two sections: the "law" of accelerating returns, and the model of the neocortex as hierarchical pattern recognizers.

## I. Linear Intuition vs. "Law" of Accelerating Returns
Kurzweil devotes a whole section to the "law" of accelerating returns. I wouldn't call it a law, but the comparison between human intuition and actual technological trajectories is worth remembering. Human intuition tends toward linear extrapolation. If something grew by 10 units last year, we instinctively expect 10 more units next year. This works well enough for day-to-day planning but fails badly for exponential processes.
The classic example is the story of the emperor and the chessboard: double a grain of rice on each square, and by the 64th square you have more rice than has ever been harvested in human history. We know this intellectually, but our gut instinct still thinks linearly.
Put another way, exponential trends look linear when you zoom too far in. Only when you sample across longer timescales does the curve reveal itself.

One of the things I love most about reading cosmology texts is how it helps prime my brain to become ever more receptive to the idea that what we physically see or experience isn't always what ***is****. *Often times, what we see covers only a relatively brief period of time and relatively small spatial distance.

If we expand our time interval and our spatial interval for which we mentally sample our world for phenomena, we find trends which stand at odds with the trends we detect at smaller intervals. We find that the earth is round; that the earth is rotating; that we are in constant acceleration; that "time" is not a constant, or barely even a real concept; that "space" curves; and that the universe itself is accelerating.

When we first measure, say, the red-shift of our universe, we could say after several minutes of observation that the universe is expanding at a linear rate. But the moment at which we expand our sampling to years, decades, we see very easily that the universe is actually expanding at an exponential rate.

I've drawn a depiction of what I mean below. Basically, we can presume linear relationships between variables when we consider small sample intervals, but when we begin to evaluate systems of larger timescales, we may find that the trend is not linear at all.

![38403331_1748855408564887_760137747431161856_n](https://nkimberly.wordpress.com/wp-content/uploads/2018/08/38403331_1748855408564887_760137747431161856_n.jpg?w=2048)

Put another way, exponential trends can look linear when we zoom too far in.
Kurzweil's point is that technological progress, particularly in computing, follows exponential trajectories that our linear intuitions systematically underestimate. His prediction is that we'll be able to create a mind by 2029. He's got a reasonable track record on predictions, so it's worth taking seriously.

## II. The Neocortex as Hierarchical Pattern Recognizers
For some background: the brain can be roughly divided into older structures (the limbic system, which includes the amygdala, hippocampus, and hypothalamus) and the neocortex. The limbic system handles emotion, memory formation, and instinctive responses. The neocortex handles higher-order cognition: learning, prediction, abstraction.
![Image result for neocortex vs amygdala](https://bookofthrees.com/images/stories/science/triune%20brain.gif)
One could be simplistic and say that the limbic system is responsible for preprogrammed instinct, which evolves slowly across generations, while the neocortex can learn within a single lifetime and make predictions based on experience.
Research has found that infant brains exhibit dense, relatively uniform wiring. As we learn, a significant portion of these connections get pruned away, leaving the circuits that experience has reinforced.
Brain imaging suggests that the neocortex contains around 300 million cortical columns, each comprising roughly 100 neurons, repeating in a relatively uniform structure across the cortical surface.
In Kurzweil's hierarchical model (which draws heavily on Jeff Hawkins's work), these modules function as pattern recognizers. Each module receives inputs from lower-level modules and outputs to higher-level ones. The modules themselves are structurally similar; what makes one "lower" or "higher" is simply its position in the recognition sequence.
![38277360_1748897505227344_2479000371008110592_n](https://nkimberly.wordpress.com/wp-content/uploads/2018/08/38277360_1748897505227344_2479000371008110592_n.jpg?w=600)

The "Apple" example: low-level recognizers detect features like the crossbar and diagonal strokes of the letter A. These feed into a module that recognizes "A" as a whole. The same happens for P, P, L, E. But here's the interesting part: you might not need all five letters. If the recognizers for A, P, and L fire, that may be enough to activate the "APPLE" module, which in turn activates your semantic concept of an apple. The same high-level module might fire when you see an image of an apple.

![38273584_1748745725242522_7408215988803469312_n](https://nkimberly.wordpress.com/wp-content/uploads/2018/08/38273584_1748745725242522_7408215988803469312_n.jpg?w=600)
This explains why we can recognize things even when parts are occluded, and why we sometimes perceive wholes that aren't fully there.
Kurzweil notes that the neocortex has expanded dramatically over mammalian evolution. Early mammalian brains had relatively smooth cortical surfaces; over time, the cortex developed more folds and ridges, increasing surface area within the same skull volume. Human foreheads grew larger to accommodate this expansion.
He also speculates that mammals survived the K-Pg extinction (the asteroid impact that killed the non-avian dinosaurs) partly because the neocortex allowed them to adapt behaviorally within their lifetimes, rather than relying solely on slower generational evolution. This is plausible as a contributing factor, though the standard explanations emphasize small body size, burrowing habits, and dietary flexibility. Early mammals had modest neocortices compared to modern humans, so it's probably not the whole story.
Rating: 7/10